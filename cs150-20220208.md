# CS 150 Class Notes 2022/02/08

## Last class: GDB, reverse debugging

How does this work? How do we go back in time?

Esp. important for non-deterministic bugs

Might be able to find with breakpoints, but being able to step backward is
helpful.

So how? options:

* Store everything at every step, replay it
  * Downside - prohibitively expensive data-wise
  * Sources of non-determinism: 
    * User input
    * Natural events
    * Pseudo-random numbers
    * input/output files based on network
* Determine what is/isn't deterministic, and re-run using the non-deterministic parts
  * Store the non-deterministic part only for replay
    * Context switches
    * System call error status
    * user input
    * other stuff

## RR: Reverse Debugging from Mozilla

What kinds of non-determinism does RR record?

* Does not record true concurrency
  * Pins all threads to a single core so that they execute sequentially
  * No efficient way to recored shared memory access

eg Signals from OS, interactions with file system (like read), system calls in general,
context switches between threads

Records things like input files, network packets, etc.

What does this mean?

* can capture single threaded issues, but can't debug issues with concurrent updates

## Lecture 6: Single Node performance debugging

Microservices:

Under traditional models, one big monolithic architecture but not very
scalable. Microservices split the application apart and have them communicate, with
each service providing specific functionality and a well-defined API

Increases velocity of development, but leaves a lot of open questions about
design philosophy.

Potentially re-usable services within the architecture.

WE DON'T KNOW HOW TO DEBUG DISTRIBUTED ARCHITECTURES

In a request in a distributed system, we have to know every step in the workflow

We're coming from an individual node, with things tacked on top - but it's
important to see the bigger picture.

### Workflow centric tracing:

GET goes through
* frontend
* client
* server
* backend storage
* server
* client
* frontend

Basic features: 

* Trace points: just like log statements, tracking important variables/
  machine state (start/ end of a function)
* Causal histories: What happens before what? (Context/ Breadcrumbs/ Metadata)
  propagating information - logical clock, request ID
  * Abstraction boundaries have to be broken. VERY complex

## CoZ: Causal Profiling of Single Node Systems

* Instead of tracking time spent, tracks potential benefits from speedups

How to tell how much a function can be sped up?

t1 -> |   F   | | G | | H | ->

t1 -> | F | | G | | H | ->

to speed up single thread, speed up slow function

2 Threads, end after all threads end

t1 -> |  F  | | G | | H | ->

t2 -> |  A  | |  B  | |    C    | ->

Speeding up F no longer matters, because thread 1 now has slack. Critical path
is thread 2 (A->B->C), aka slowest path that overall execution time depends.

Should probably speed up C, but what if I don't want to put in the effort?

Slow down other threads by x% - once there is no slack left, improving C no
longer helps.
