# CS 150 Class Notes 2022/03/08

Startup Notes:

* Better specifications, better chance of success

## Intro to Distributed Tracing

### What is Distributed Tracing?

* Collect data about work performed from a specific startpoint
* Trace causality in case of failure
* Collect identifiers
* Uses tracepoints

### Problem

As services grow more complex, from service to system centric

How to understand behaviour, analyze error sources.

### X-Trace

Causality based, very granular

* Event based tracing - which events happened before/ caused other events
  * Events are grouped into tasks
  * Trace points in source code create events
  * Events have info stored in reports and sent elsewhere (reqd out of bound 
    service)
  * X-Trace carries metadata throughout task
* Outputs task graph visualizer

Different from regular logging, because distinct ordering through metadata
(developers have to ensure that they are propagating the context along 
properly).

---

Case Studies

* IEEE 802.1X authentication, CoralCDN and OASIS anycast
  * Search for causes of bugs/ perf issues using causal tracing
  * Able to find new bugs
  * Using tracing, able to tune timeouts and synchronize clocks better

---

Shortcomings:

* Semantic v Incidental concurrency - In forks, X-Trace will not always output
  correct semantic order, but requires manual editing to correct it.
  * Problem: the fork itself has to propagate context (as does join)
* Programmer themselves has to pass the data around
* Side-by-Side may have been helpful

### Dapper

RPC/ Span based

* Timestamps with edges defined by caller-callee
* Traces made of nodes (spans) with annotations
  * Start/Stop
  * When does X get call
  * When does X call Y
* Using sampling to mitigate overhead
  * tracing most things, but not absolutely everything
  * Should still be a representative sample
* Comes with interactive UI

---

How do we know it works? Lots of case studies over multiple years

Adaptave Sampling (a key tenet):

* Logs make it through the daemon corresponding to the level of throughput.
  more activity, more selective sampling. At lower rates, less selective.
  Sampling decision is made upon entry
* Lots of testing as tool was discoverable and easy to use
* Interesting cases:
  * Addressing long tail latency (network lag on e2e perf)
    (expensive dependencies increasing latency)
  * Inferring service dependencies (picks up when multiple jobs depend on same
    infrastructure) 
  * Pinpointing resource consumption

---

Improvements:

* Coalescing effects (Only one traced request at a time, making multiple 
  request processes look slower than it is)
* Tracing batch workloads (offline data not gathered)
* Fidning root cause (can only find where slowdown is)
* Logging kerel-level information (syscalls are not recorded)
* Limitation of Tracing non-instrumented communication (sockets, SOAP)

### Tracing Methods

Event v Span

* Event
  * happens-before (causal accuracy)
  * higher space complexity
* Span
  * Simpler graph
  * relations are caller-callee

What do developers think? Span-based is seemingly the winner, for ease of
implementation (and most times stuff is on-prem)


