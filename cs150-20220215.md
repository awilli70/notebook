# CS 150 Class Notes 2022/02/15

So... we were talking about CoZ.

Previously, dealing with single node tools (like perf, gprof, etc.)

How do they work?

* Randomly sample functions to profile during execution
* Records many performance related events
* Common use case: Show slowest functions as per CPU-time used

Can also show stats re: page faults, tlb misses, log points in kernel

Why doesn't this work for multi-threaded programs?

* Bottlenecks and Slack - looking at the slowest function doesn't tell
  the whole story, because it may be waiting for one or more other functions
  to complete.
* Misses critical paths (the slowest concurrent thread/ path to program end)

ASCII DIAGRAM

             start
            /     \
        f1():2s f2():50s
           |       |
       f3():90s f5():50s
            \    /
             end

CRITICAL PATH is of f2 and f5 (total 100s vs 92)

### Visualization

Flame graphs:

* Width is time of execution across samples, and functions stacked on top
  are the functions it called. Gets a sense of where slowdowns are by func

## CoZ review

> F G F
>
> G H G

f-10 g-5 h-8 $T_o = 25s$, slack of 7s

**Speed up f 50%**

> F &nbsp;&nbsp; &nbsp;&nbsp;G &nbsp;&nbsp;&nbsp;&nbsp; F
>
> G /5s/ G H /5s/ H G 

Critical path time: (10 + 5 + 5 + 8 = 28)

Slack decreases to 3s going the other way, speedup of 7s

$T_o = 25 + \texttt{delay} = 35s$, 

$T_s = T_o + \texttt{critical path time} = 35 - 28 = 7s$

Speedup pctg = $1 - (T_o - T_s)/T_o$

### But how?

* Developers id regions of interest in code via annotations
* CoZ randomly picks fn and speedup %
* CoZ samples ProgCtr to check which function is executing, dynamically
  dynamically slows down other stuff.

## 99th percentile, part 2

Latency is not distributed uniformly, but we look at "Bins" of 
latency, and the 99% latency is the top 1% of all requests in the higher latency bins.

Use 99th percentile for scatter-aggregate pattern, where we are
reliant upon the latency of every single node

Probability request is slow is 1 minus the probability all requests
are fast (1 - 99th percentile)

Also important as a measure of system predictability (bounding the 
badness, not necessarily the distribution)

BUT lower variance likely better
